{
    "name": "root",
    "gauges": {
        "FullGame.Policy.Entropy.mean": {
            "value": 0.38833510875701904,
            "min": 0.3173314332962036,
            "max": 0.9570035934448242,
            "count": 713
        },
        "FullGame.Policy.Entropy.sum": {
            "value": 726.9633178710938,
            "min": 581.3511962890625,
            "max": 1944.63134765625,
            "count": 713
        },
        "FullGame.Environment.EpisodeLength.mean": {
            "value": 252.5,
            "min": 22.0,
            "max": 499.0,
            "count": 713
        },
        "FullGame.Environment.EpisodeLength.sum": {
            "value": 2525.0,
            "min": 66.0,
            "max": 3798.0,
            "count": 713
        },
        "FullGame.Step.mean": {
            "value": 9119896.0,
            "min": 7695950.0,
            "max": 9119896.0,
            "count": 713
        },
        "FullGame.Step.sum": {
            "value": 9119896.0,
            "min": 7695950.0,
            "max": 9119896.0,
            "count": 713
        },
        "FullGame.Policy.ExtrinsicValueEstimate.mean": {
            "value": 4.470101833343506,
            "min": 2.853057861328125,
            "max": 5.981517791748047,
            "count": 713
        },
        "FullGame.Policy.ExtrinsicValueEstimate.sum": {
            "value": 84.93193054199219,
            "min": 52.88068389892578,
            "max": 110.77698516845703,
            "count": 713
        },
        "FullGame.Environment.CumulativeReward.mean": {
            "value": 110.06666649712457,
            "min": 7.600000063578288,
            "max": 247.0,
            "count": 713
        },
        "FullGame.Environment.CumulativeReward.sum": {
            "value": 990.5999984741211,
            "min": 22.800000190734863,
            "max": 1784.9999978542328,
            "count": 713
        },
        "FullGame.Policy.ExtrinsicReward.mean": {
            "value": 110.06666649712457,
            "min": 7.600000063578288,
            "max": 247.0,
            "count": 713
        },
        "FullGame.Policy.ExtrinsicReward.sum": {
            "value": 990.5999984741211,
            "min": 22.800000190734863,
            "max": 1784.9999978542328,
            "count": 713
        },
        "FullGame.Losses.PolicyLoss.mean": {
            "value": 0.14456941207523819,
            "min": 0.11417533821399155,
            "max": 0.1592775646123646,
            "count": 713
        },
        "FullGame.Losses.PolicyLoss.sum": {
            "value": 0.867416472451429,
            "min": 0.37659294344484806,
            "max": 1.1149429522865524,
            "count": 713
        },
        "FullGame.Losses.ValueLoss.mean": {
            "value": 0.05173892581393246,
            "min": 0.01829981787671352,
            "max": 2.5952264989415803,
            "count": 713
        },
        "FullGame.Losses.ValueLoss.sum": {
            "value": 0.31043355488359475,
            "min": 0.10413004348561346,
            "max": 7.785679496824741,
            "count": 713
        },
        "FullGame.Policy.LearningRate.mean": {
            "value": 0.0002452865062378374,
            "min": 0.0002452865062378374,
            "max": 0.00025382695939101863,
            "count": 713
        },
        "FullGame.Policy.LearningRate.sum": {
            "value": 0.0014717190374270244,
            "min": 0.0007614808781730559,
            "max": 0.0017762217419261218,
            "count": 713
        },
        "FullGame.Policy.Epsilon.mean": {
            "value": 0.1817621626666667,
            "min": 0.1817621626666667,
            "max": 0.18460898133333337,
            "count": 713
        },
        "FullGame.Policy.Epsilon.sum": {
            "value": 1.0905729760000002,
            "min": 0.5538269440000001,
            "max": 1.2920738779999998,
            "count": 713
        },
        "FullGame.Policy.Beta.mean": {
            "value": 0.004089931917066667,
            "min": 0.004089931917066667,
            "max": 0.004231988168533333,
            "count": 713
        },
        "FullGame.Policy.Beta.sum": {
            "value": 0.024539591502400003,
            "min": 0.0126959645056,
            "max": 0.0296144865122,
            "count": 713
        },
        "FullGame.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 713
        },
        "FullGame.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 713
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1637323591",
        "python_version": "3.7.11 (default, Jul 27 2021, 09:42:29) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\mhaag\\anaconda3\\envs\\dl\\Scripts\\mlagents-learn trainingconfigs\\ppo_basic.yaml --run-id=18_11_contact --resume",
        "mlagents_version": "0.27.0",
        "mlagents_envs_version": "0.27.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.0+cu110",
        "numpy_version": "1.19.5",
        "end_time_seconds": "1637327672"
    },
    "total": 4080.9569304,
    "count": 1,
    "self": 0.009829700000409503,
    "children": {
        "run_training.setup": {
            "total": 0.15087590000000017,
            "count": 1,
            "self": 0.15087590000000017
        },
        "TrainerController.start_learning": {
            "total": 4080.7962248,
            "count": 1,
            "self": 3.7593355999779305,
            "children": {
                "TrainerController._reset_env": {
                    "total": 9.5627632,
                    "count": 1,
                    "self": 9.5627632
                },
                "TrainerController.advance": {
                    "total": 4067.345326900022,
                    "count": 181417,
                    "self": 4.139007399953243,
                    "children": {
                        "env_step": {
                            "total": 2468.563349399995,
                            "count": 181417,
                            "self": 2045.2999526000337,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 420.9232291999536,
                                    "count": 181417,
                                    "self": 11.877867399963861,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 409.04536179998973,
                                            "count": 178242,
                                            "self": 158.15722599998145,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 250.88813580000829,
                                                    "count": 178242,
                                                    "self": 250.88813580000829
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 2.3401676000075664,
                                    "count": 181416,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 4070.5096239000554,
                                            "count": 181416,
                                            "is_parallel": true,
                                            "self": 2239.318323600042,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0004637999999994591,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00024229999999914043,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00022150000000031866,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00022150000000031866
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1831.1908365000136,
                                                    "count": 181416,
                                                    "is_parallel": true,
                                                    "self": 14.525050499922145,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 77.54238570002042,
                                                            "count": 181416,
                                                            "is_parallel": true,
                                                            "self": 77.54238570002042
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1679.6122572000058,
                                                            "count": 181416,
                                                            "is_parallel": true,
                                                            "self": 1679.6122572000058
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 59.51114310006508,
                                                            "count": 181416,
                                                            "is_parallel": true,
                                                            "self": 31.11045220003255,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 28.400690900032526,
                                                                    "count": 362832,
                                                                    "is_parallel": true,
                                                                    "self": 28.400690900032526
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1594.6429701000739,
                            "count": 181416,
                            "self": 6.612579400152072,
                            "children": {
                                "process_trajectory": {
                                    "total": 261.6082715999216,
                                    "count": 181416,
                                    "self": 260.7825485999212,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.8257230000003801,
                                            "count": 3,
                                            "self": 0.8257230000003801
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 1326.4221191000001,
                                    "count": 4260,
                                    "self": 238.72986590000596,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 1087.6922531999942,
                                            "count": 128493,
                                            "self": 1087.6922531999942
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.2000000424450263e-06,
                    "count": 1,
                    "self": 1.2000000424450263e-06
                },
                "TrainerController._save_models": {
                    "total": 0.12879789999988134,
                    "count": 1,
                    "self": 0.009611899999981688,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.11918599999989965,
                            "count": 1,
                            "self": 0.11918599999989965
                        }
                    }
                }
            }
        }
    }
}